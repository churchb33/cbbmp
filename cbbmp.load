#' Download data from Chesapeake Bay Benthic Monitoring Program
#' 
#' This function takes a range of years (from 1995 through newest available year -- see URL below for
#' currently available year) and returns a data.frame of biomass, sediment quality, and water quality
#' parameters from both the Maryland and Virginia datasets from the range of years.
#' 
#'  
#' @param years The range of years of sampling data to download; minimum = 1995, maximum is updated annually, but current maximum = 2013
#' 
#' @param path An alternative repository for data files downloaded by cbbmp.load; default repository is the working directory; new file path does not alter working directory
#' 
#' @param save Logical option to save Rdata file of downloaded data for future reference; default setting will save a file called 'cbbmp.Rdata' to the specified file path or, by default, the working directory
#' 
#' @return data.frame
#' 
#' @import plyr, reshape2, magrittr
#' 
#' @seealso \url{http://www.baybenthos.versar.com/data.htm}
#' 
#' @section Warning:
#' It is strongly recommended that, if you do not set save=TRUE, that you create an R object from the output of the function. Successive executions of the function will cause the data to download on each execution.
#' The full dataset can be quite large, so relying on compressed Rdata file is recommended rather than writing to other formats (e.g., .csv, .xlsx).
#' Loading the data causes consistent warnings that NAs are produced. This is to be expected. The NA values are caused by slight inconsistencies in data columns between years.
#' 
#' @export

cbbmp.load<-function(years, path=getwd(), save=TRUE){ 
  
  ##error out if the years are beyond the possible range of datasets
  
  if (min(years) < 1995) {stop("data not available before 1995")}
  
  if (max(years) >= as.numeric(format(Sys.Date(), "%Y"))) 
    {stop("data for the current or future years are not available")}

  ## allows for alternate file destination  

  directory <- getwd()

  setwd(path)

  base.url <- "http://www.baybenthos.versar.com/SciData/"

  table.ext <- c("bm.txt", "sed.txt", "wq.txt")

  region <- c("mdbe", "vabe") 
 

  year.url <- paste0("CBPData", years)

  region.year <- c(paste0(region[[1]], substr(years, start=3, stop=4)),
               paste0(region[[2]], substr(years, start=3, stop=4)))

  url.main<-paste0(base.url,year.url,"/",region.year,"_")

  full.url <-c(paste0(url.main,table.ext[[1]]),
    paste0(url.main,table.ext[[2]]),
    paste0(url.main,table.ext[[3]]))

  filepath <-c(paste0(region.year,"_",table.ext[[1]]),
    paste0(region.year,"_",table.ext[[2]]),
    paste0(region.year,"_",table.ext[[3]]))


    
  for (i in 1:length(full.url)) {
    download.file(full.url[i], destfile = filepath[i], mode="wb")
  }
  

  #note there are (year * region) datasets per type, and 3 types

  gap.y <- (length(years)) * 2  

  gap.z <- (length(years)) * 2 * 2
 
  options(stringsAsFactors=FALSE)

  v.m <- list()
  
  for (i in 1:length(years)) {  
  
    #x is the biomass data for maryland
    x <- read.csv(filepath[i], row.names= NULL)
 
    colnames(x) <- colnames(x)[-1]
  
    x <- x[-length(x)]

    x$LKUP <- paste(x$STATION, x$YEARCODE, x$SAMPLE_NUMBER)

    ##converting missing value notation to NA and VALUE to numeric
    ##not necessary for bm datasets, but is for wq and sed
    x$VALUE <- as.numeric(gsub(pattern= "       .    ",
      replacement= NA, fixed= TRUE, x= x$VALUE))
    x$REGION <- "Maryland"
  
    
    x <- x %>% dplyr::filter(LBL == "Macoma balthica") 
    
    x <- reshape2::dcast(x, 
    formula = REGION + YEARCODE+ STATION + SAMPLE_NUMBER ~ PARAMETER + UNITS, 
    fun.aggregate= mean, na.rm= TRUE,
    value.var= "VALUE")
  
    ##y is the sediment characteristic data for maryland
    y <- read.csv(as.character(filepath[i + gap.y]), row.names=NULL)

    colnames(y) <- colnames(y)[-1]

    y <- y[-length(y)]

    colnames(y)[length(y)] <- "SAMP_TYPE"


    y$LKUP <- paste(y$STATION, y$YEARCODE, y$SAMPLE_NUMBER)

    y$VALUE <- as.numeric(gsub(pattern= "       .    ",
      replacement= NA, fixed= TRUE, x= y$VALUE))
    y$REGION <- "Maryland"

        
    y <- reshape2::dcast(y, 
      formula = LKUP ~ PARAMETER + UNITS, 
      fun.aggregate=mean, na.rm=TRUE,
      value.var= "VALUE")
    

    ##z is the water quality data for maryland
    z <- read.csv(filepath[i + gap.z], row.names= NULL)
    colnames(z) <- colnames(z)[-1]
    z <- z[-length(z)]
    colnames(z)[length(z)] <- "SAMP_TYPE"
    z$LKUP <- paste(z$STATION, z$YEARCODE, z$SAMPLE_NUMBER)
    z$VALUE <- as.numeric(z$VALUE)
    z$REGION <- "Maryland"

    z <- reshape2::dcast(z, 
    formula = LKUP ~ PARAMETER + UNITS, 
    fun.aggregate=mean, na.rm=TRUE,
    value.var= "VALUE")
    
    
    #a is the biomass data for the virginia province
    a <- read.csv(filepath[i + 1], row.names= NULL)
  
    colnames(a) <- colnames(a)[-1]
  
    a <- a[-length(a)]

    a$LKUP <- paste(a$STATION, a$YEARCODE, a$SAMPLE_NUMBER)


    a$VALUE <- as.numeric(gsub(pattern= "       .    ",
      replacement= NA, fixed= TRUE, x= a$VALUE))
    a$REGION <- "Virginia"

    a <- a %>% dplyr::filter(LBL == "Macoma balthica") 

    a <- reshape2::dcast(a, 
      formula = REGION + YEARCODE + STATION + SAMPLE_NUMBER ~ PARAMETER + UNITS, 
      fun.aggregate=mean, na.rm=TRUE,
      value.var= "VALUE")
  
    
    
    ##b is the sediment characteristic data, virginia province
    b <- read.csv(as.character(filepath[i + 1 + gap.y]), row.names=NULL)

    colnames(b) <- colnames(b)[-1]

    b <- b[-length(b)]

    colnames(b)[length(b)] <- "SAMP_TYPE"

    b$LKUP <- paste(b$STATION, b$bEARCODE, b$SAMPLE_NUMBER)

    b$VALUE <- as.numeric(gsub(pattern= "       .    ",
      replacement= NA, fixed= TRUE, x= b$VALUE))
    b$REGION <- "Virginia"

    b <- reshape2::dcast(b, 
    formula = LKUP ~ PARAMETER + UNITS, 
    fun.aggregate=mean, na.rm=TRUE,
    value.var= "VALUE")
  
    
    
    ##c is the water quality data, virginia province
    c <- read.csv(filepath[i + 1 + gap.z], row.names= NULL)
    
    colnames(c) <- colnames(c)[-1]
    
    c <- c[-length(c)]
    
    colnames(c)[length(c)] <- "SAMP_TYPE"
    
    c$LKUP <- paste(c$STATION, c$YEARCODE, c$SAMPLE_NUMBER)
    
    c$VALUE <- as.numeric(c$VALUE)
    
    c$REGION <- "Virginia"
    
    c <- reshape2::dcast(c, 
    formula = LKUP ~ PARAMETER + UNITS, 
    fun.aggregate=mean, na.rm=TRUE,
    value.var= "VALUE")

    ##Joining abcdxyz using smartbind (requires 'gtools' package)
    merge.m <- dplyr::left_join(x, y, by = LKUP)
    merge.m <- dplyr::left_join(merge.m, z, by = LKUP)

    merge.v <- dplyr::left_join(a, b, by = LKUP)
    merge.v <- dplyr::left_join(merge.v, c, by = LKUP)

    merge <- plyr::rbind.fill(merge.m, merge.v)
    
    v.m[[i]] <- merge
    
  }


  ##combine all years into single dataset  
  cbbmp <- do.call(plyr::rbind.fill, v.m)    
  
  ##remove superfluous and inconsistently reported columns  
  var.delete <- c("SAMPLE_DEPTH", "PARTITON", "STRATUM", "SITE", "SITE_TYPE", "TIME",
    "STAEQ85","STAEQ89","NET_MESH","SOURCE")    
    
  var.filter <-names(cbbmp)[! (names(cbbmp) %in% var.delete)]

  cbbmp <- subset(x = cbbmp, select = var.filter)
 
 
  
  ##option to save dataset for quick future reference    
  if(save)     {
    setwd(directory)
    saveRDS(cbbmp, file= "cbbmp.Rdata")
    unlink("cbbmp.Rdata")
  }
  setwd(directory)  
  return(cbbmp)
}

getwd()

T<-cbbmp.load(years=1995)


